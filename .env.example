# Environment Configuration Template
# Copy this file to .env and customize as needed

# ======================
# OLLAMA CONFIGURATION
# ======================

# Ollama host URL (adjust based on your setup)
# For Docker Desktop (Windows/macOS): http://host.docker.internal:11434
# For Docker on Linux: http://172.17.0.1:11434
# For Docker Compose with ollama service: http://ollama:11434
OLLAMA_HOST=http://ollama:11434

# ======================
# BACKEND CONFIGURATION
# ======================

# Backend environment (development, production)
ENVIRONMENT=production

# API host and port
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000

# CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# ======================
# FRONTEND CONFIGURATION
# ======================

# API URL for frontend to connect to backend
REACT_APP_API_URL=http://localhost:8000

# Enable polling for file changes in Docker (development only)
CHOKIDAR_USEPOLLING=true
WATCHPACK_POLLING=true

# ======================
# DOCKER CONFIGURATION
# ======================

# Docker Compose project name
COMPOSE_PROJECT_NAME=llm-benchmark

# ======================
# GPU SUPPORT (NVIDIA)
# ======================

# Uncomment to enable GPU support for Ollama
# NVIDIA_VISIBLE_DEVICES=all
# NVIDIA_DRIVER_CAPABILITIES=compute,utility

# ======================
# LOGGING
# ======================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# ======================
# SECURITY
# ======================

# Secret key for session management (generate a random string)
SECRET_KEY=your-super-secret-key-change-this-in-production

# ======================
# PERFORMANCE
# ======================

# Number of worker processes for backend
WORKERS=1

# Timeout settings
REQUEST_TIMEOUT=300
OLLAMA_TIMEOUT=300
